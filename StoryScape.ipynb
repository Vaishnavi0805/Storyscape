{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Story Scape\n",
        "- StoryScape is an AI-powered app for kids that creates captivating story videos based on user prompts. Unlock your imagination and dive into a world of endless storytelling with StoryScape."
      ],
      "metadata": {
        "id": "rXbNBben2ONC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the required libraries"
      ],
      "metadata": {
        "id": "XTgiCyMy2a3b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHsmsY1V2Bs6"
      },
      "outputs": [],
      "source": [
        "if \"google.colab\" in str(get_ipython()):\n",
        "    ! pip3 install --upgrade google-cloud-aiplatform\n",
        "    from google.colab import auth as google_auth\n",
        "\n",
        "    google_auth.authenticate_user()\n",
        "    ! pip3 install --upgrade pip\n",
        "    ! pip3 install torchvision==0.14.1\n",
        "    ! pip3 install transformers==4.27.1\n",
        "    ! pip3 install diffusers==0.15.1\n",
        "    ! pip3 install datasets==2.9.0\n",
        "    ! pip3 install accelerate==0.18.0\n",
        "    ! pip3 install triton==2.0.0.dev20221120\n",
        "    ! pip3 install xformers==0.0.16\n",
        "    # Install gdown for downloading example training images.\n",
        "    ! pip3 install gdown\n",
        "    # Remove wrong cublas version.\n",
        "    ! pip3 uninstall nvidia_cublas_cu11 --yes\n",
        "\n",
        "    # Restart the notebook kernel after installs.\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)\n",
        "!pip install google-cloud-texttospeech\n",
        "from google.cloud import storage\n",
        "from google.cloud import texttospeech\n",
        "import re\n",
        "import vertexai\n",
        "from vertexai.language_models import TextGenerationModel\n",
        "!pip install moviepy\n",
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c460088b873"
      },
      "source": [
        "Fill following variables for experiments environment:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cloud project id.\n",
        "\n",
        "\n",
        "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# The region you want to launch jobs in.\n",
        "REGION = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# The Cloud Storage bucket for storing experiments output. Fill it without the 'gs://' prefix.\n",
        "GCS_BUCKET = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# The service account for deploying fine tuned model.\n",
        "SERVICE_ACCOUNT = \"\"  # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "TiyCkU5O2rN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e828eb320337"
      },
      "source": [
        "Initialize Vertex-AI API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12cd25839741"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cc825514deb"
      },
      "source": [
        "### Define constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b42bd4fa2b2d"
      },
      "outputs": [],
      "source": [
        "# The pre-built training docker image. It contains training scripts and models.\n",
        "TRAIN_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/pytorch-diffusers-train:latest\"\n",
        "\n",
        "# The pre-built serving docker image. It contains serving scripts and models.\n",
        "SERVE_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/pytorch-diffusers-serve\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '<path to credentials file of your service account>'\n",
        "!ls -l $GOOGLE_APPLICATION_CREDENTIALS"
      ],
      "metadata": {
        "id": "ziD1EjHu2rWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "from google.cloud import storage\n",
        "from google.cloud import texttospeech\n",
        "import vertexai\n",
        "from vertexai.language_models import TextGenerationModel\n",
        "import re\n",
        "from google.cloud import aiplatform\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from moviepy.editor import VideoClip, AudioFileClip, ImageClip, VideoFileClip\n",
        "from moviepy.video.compositing.concatenate import concatenate_videoclips\n",
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "# The region you want to launch jobs in.\n",
        "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
        "# The Cloud Storage bucket for storing experiments output. Fill it without the 'gs://' prefix.\n",
        "GCS_BUCKET = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# The service account for deploying fine tuned model.\n",
        "SERVICE_ACCOUNT = \"\"  # @param {type:\"string\"}\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)\n",
        "PROJECT_ID = \"\"\n",
        "vertexai.init(project=PROJECT_ID, location=\"\")\n",
        "# The pre-built training docker image. It contains training scripts and models.\n",
        "TRAIN_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/pytorch-diffusers-train:latest\"\n",
        "\n",
        "# The pre-built serving docker image. It contains serving scripts and models.\n",
        "SERVE_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai-restricted/vertex-vision-model-garden-dockers/pytorch-diffusers-serve\"\n",
        "\n",
        "import base64\n",
        "import glob\n",
        "import os\n",
        "from datetime import datetime\n",
        "from io import BytesIO\n",
        "\n",
        "import requests\n",
        "from google.cloud import aiplatform, storage\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def create_job_name(prefix):\n",
        "    user = os.environ.get(\"USER\")\n",
        "    now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    job_name = f\"{prefix}-{user}-{now}\"\n",
        "    return job_name\n",
        "\n",
        "\n",
        "def download_image(url):\n",
        "    response = requests.get(url)\n",
        "    return Image.open(BytesIO(response.content))\n",
        "\n",
        "\n",
        "def image_to_base64(image, format=\"JPEG\"):\n",
        "    buffer = BytesIO()\n",
        "    image.save(buffer, format=format)\n",
        "    image_str = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
        "    return image_str\n",
        "\n",
        "\n",
        "def base64_to_image(image_str):\n",
        "    image = Image.open(BytesIO(base64.b64decode(image_str)))\n",
        "    return image\n",
        "\n",
        "\n",
        "def image_grid(imgs, rows=2, cols=2):\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new(\"RGB\", size=(cols * w, rows * h))\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
        "    return grid\n",
        "\n",
        "\n",
        "def deploy_model(model_id, task):\n",
        "    model_name = \"stable-diffusion-v1\"\n",
        "    endpoint = aiplatform.Endpoint.create(display_name=f\"{model_name}-{task}-endpoint\")\n",
        "    serving_env = {\n",
        "        \"MODEL_ID\": model_id,\n",
        "        \"TASK\": task,\n",
        "    }\n",
        "    model = aiplatform.Model.upload(\n",
        "        display_name=model_name,\n",
        "        serving_container_image_uri=SERVE_DOCKER_URI,\n",
        "        serving_container_ports=[7080],\n",
        "        serving_container_predict_route=\"/predictions/diffusers_serving\",\n",
        "        serving_container_health_route=\"/ping\",\n",
        "        serving_container_environment_variables=serving_env,\n",
        "    )\n",
        "    model.deploy(\n",
        "        endpoint=endpoint,\n",
        "        machine_type=\"n1-standard-8\",\n",
        "        accelerator_type=\"NVIDIA_TESLA_V100\",\n",
        "        accelerator_count=1,\n",
        "        deploy_request_timeout=1800,\n",
        "        service_account=SERVICE_ACCOUNT,\n",
        "    )\n",
        "    return model, endpoint\n",
        "\n",
        "\n",
        "def get_bucket_and_blob_name(filepath):\n",
        "    # The gcs path is of the form gs://<bucket-name>/<blob-name>\n",
        "    gs_suffix = filepath.split(\"gs://\", 1)[1]\n",
        "    return tuple(gs_suffix.split(\"/\", 1))\n",
        "\n",
        "\n",
        "def upload_local_dir_to_gcs(local_dir_path, gcs_dir_path):\n",
        "    \"\"\"Uploads files in a local directory to a GCS directory.\"\"\"\n",
        "    client = storage.Client()\n",
        "    bucket_name = gcs_dir_path.split(\"/\")[2]\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    for local_file in glob.glob(local_dir_path + \"/**\"):\n",
        "        if not os.path.isfile(local_file):\n",
        "            continue\n",
        "        filename = local_file[1 + len(local_dir_path) :]\n",
        "        gcs_file_path = os.path.join(gcs_dir_path, filename)\n",
        "        _, blob_name = get_bucket_and_blob_name(gcs_file_path)\n",
        "        blob = bucket.blob(blob_name)\n",
        "        blob.upload_from_filename(local_file)\n",
        "        print(\"Copied {} to {}.\".format(local_file, gcs_file_path))\n",
        "\n",
        "\n",
        "\n",
        "def generate_output(input_text):\n",
        "    # Add your logic here to process the input text and generate the desired output\n",
        "    input = f\"You entered: {input_text}\"\n",
        "    return input\n",
        "\n",
        "def story():\n",
        "    st.title(\"Text Input App\")\n",
        "    input_text = st.text_input(\"Enter your text:\")\n",
        "    prompt = generate_output(input_text)\n",
        "    if prompt.strip() != \"\":\n",
        "        final_prompt=f\"\"\"Act as a story writer who specialize in children's stories. Your task is to write a 500 words story based on {prompt} and take help of additional tasks given below:\n",
        "                    This story will have a proper title and a meaningful short moral\n",
        "                    The story should be based on characters or things mentioned in {prompt} you should not assume other things.\n",
        "                    If {prompt} doesn't have enough context create title using your intelligence\n",
        "                    If in {prompt} the characters don't have name give them one fictional name\n",
        "                    Your objective is to communicate a useful message for children to learn from  \"\"\"\n",
        "        vertexai.init(project=\"first-grove-392012\", location=\"us-central1\")\n",
        "        parameters = {\n",
        "            \"temperature\": 0.5,\n",
        "            \"max_output_tokens\": 500,\n",
        "            \"top_p\": 0.8,\n",
        "            \"top_k\": 40\n",
        "        }\n",
        "        model = TextGenerationModel.from_pretrained(\"text-bison\")\n",
        "        response = model.predict(\n",
        "          final_prompt,\n",
        "            **parameters\n",
        "        )\n",
        "        return response.text\n",
        "    else:\n",
        "        return f\"Prompt is empty. No story will be generated.\"\n",
        "\n",
        "def divided_story(story_text):\n",
        "    story = story_text.replace('\\n', ' ')\n",
        "    story = story_text.replace('*', ' ')\n",
        "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', story)\n",
        "\n",
        "    # Ensure there are at least two sentences in the story\n",
        "    if len(sentences) < 2:\n",
        "        raise ValueError(\"The story should contain at least two sentences.\")\n",
        "\n",
        "    # Group the sentences into pairs\n",
        "    sentence_pairs = [sentences[i] + ' ' + sentences[i+1] for i in range(0, len(sentences) - 1, 2)]\n",
        "\n",
        "    # If there is an odd number of sentences, keep the last sentence as it is\n",
        "    if len(sentences) % 2 != 0:\n",
        "        sentence_pairs.append(sentences[-1])\n",
        "\n",
        "    return sentence_pairs\n",
        "\n",
        "story_text = story()\n",
        "\n",
        "\n",
        "def audio():\n",
        "    story_ls = divided_story(story_text)\n",
        "    project_id = ''\n",
        "    client = storage.Client(project=project_id)\n",
        "    bucket_name = 'bucket-innovaite'\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '<path to credentials file of your service account>'\n",
        "    speech_client = texttospeech.TextToSpeechClient()\n",
        "    # Delete existing files in the bucket\n",
        "    blobs = bucket.list_blobs()\n",
        "    for blob in blobs:\n",
        "        blob.delete()\n",
        "        print(f'Deleted file: {blob.name}')\n",
        "    for i in range(len(story_ls)):\n",
        "        input_text = texttospeech.SynthesisInput(text=story_ls[i])\n",
        "        voice = texttospeech.VoiceSelectionParams(\n",
        "        language_code=\"en-US\",\n",
        "        name=\"en-US-Studio-O\",\n",
        "        )\n",
        "\n",
        "        audio_config = texttospeech.AudioConfig(\n",
        "            audio_encoding=texttospeech.AudioEncoding.LINEAR16,\n",
        "            speaking_rate=1\n",
        "        )\n",
        "\n",
        "        response = speech_client.synthesize_speech(\n",
        "            request={\"input\": input_text, \"voice\": voice, \"audio_config\": audio_config}\n",
        "        )\n",
        "\n",
        "        # The response's audio_content is binary.\n",
        "        audio_filename=f\"output{i+10}.mp3\"\n",
        "        with open(audio_filename, \"wb\") as out:\n",
        "            out.write(response.audio_content)\n",
        "            object_name_in_gcs_bucket = bucket.blob(audio_filename)\n",
        "            object_name_in_gcs_bucket.upload_from_filename(audio_filename)\n",
        "\n",
        "\n",
        "            print(f'Audio content written to file {audio_filename}')\n",
        "def image():\n",
        "    aud=audio()\n",
        "    story_ls = divided_story(story_text)\n",
        "    project_id = ''\n",
        "    client = storage.Client(project=project_id)\n",
        "    bucket_name = 'image_storygen'\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    blobs = bucket.list_blobs()\n",
        "    for blob in blobs:\n",
        "        blob.delete()\n",
        "        print(f'Deleted file: {blob.name}')\n",
        "    for i in range(len(story_ls)):\n",
        "        prompt = f'''Generate an image that represents the scene: {story_ls[i]} with the help of the following task and context given below:\n",
        "        1.Take the context by using summary of {story_ls} to generate best image for {story_ls[i]}\n",
        "        2.Keep the image theme for {story_ls} vibrant, comic like,3D Cartoon Style.\n",
        "        3.Do not include any text inside the image.\n",
        "        4.Keep the same theme throughout the {story_ls}'''\n",
        "\n",
        "        results = pipe(prompt=prompt, guidance_scale=25)\n",
        "        images = results.images\n",
        "        nsfw_detects = results.nsfw_content_detected\n",
        "\n",
        "        # Save the image file\n",
        "        image_filename = f\"image{i+10}.png\"\n",
        "        images[0].save(image_filename)\n",
        "\n",
        "        # Upload the image file to Google Cloud Storage\n",
        "        object_name_in_gcs_bucket = bucket.blob(image_filename)\n",
        "        object_name_in_gcs_bucket.upload_from_filename(image_filename)\n",
        "\n",
        "        print(f'Image file {image_filename} saved and uploaded.')\n",
        "\n",
        "def merge_audio_image(audio_bucket_name, image_bucket_name, output_file, video_bucket_name):\n",
        "    img=image()\n",
        "    storage_client = storage.Client()\n",
        "\n",
        "    audio_bucket = storage_client.get_bucket(audio_bucket_name)\n",
        "    image_bucket = storage_client.get_bucket(image_bucket_name)\n",
        "    video_bucket = storage_client.get_bucket(video_bucket_name)\n",
        "\n",
        "    audio_files = audio_bucket.list_blobs()\n",
        "    image_files = image_bucket.list_blobs()\n",
        "\n",
        "    audio_files_sorted = sorted(audio_files, key=lambda file: file.name)\n",
        "    image_files_sorted = sorted(image_files, key=lambda file: file.name)\n",
        "\n",
        "    video_clips = []\n",
        "    for audio_file, image_file in zip(audio_files_sorted, image_files_sorted):\n",
        "        audio_path = audio_file.name\n",
        "        image_path = image_file.name\n",
        "\n",
        "        audio_clip = AudioFileClip(audio_path)\n",
        "        image_clip = ImageClip(image_path)\n",
        "\n",
        "        # Set the duration of the image clip to match the audio clip's duration\n",
        "        image_clip = image_clip.set_duration(audio_clip.duration)\n",
        "\n",
        "        # Set the audio of the image clip to match the audio clip\n",
        "        image_clip = image_clip.set_audio(audio_clip)\n",
        "\n",
        "        # Append the image clip to the video clips list\n",
        "        video_clips.append(image_clip)\n",
        "\n",
        "    # Concatenate the video clips to create the final video\n",
        "    final_video = concatenate_videoclips(video_clips)\n",
        "    # Write the final video to the output file\n",
        "    final_video.write_videofile(output_file, codec=\"libx264\", audio_codec=\"aac\", fps=24)\n",
        "\n",
        "    # Upload the video file to the video bucket\n",
        "    video_blob = video_bucket.blob(output_file)\n",
        "    video_blob.upload_from_filename(output_file)\n",
        "    video_bucket_name = \"video_storygen\"\n",
        "    video_file_name = \"output.mp4\"\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Specify the names of the audio, image, and video buckets, and the output file path\n",
        "    audio_bucket_name = \"bucket-innovaite\"\n",
        "    image_bucket_name = \"image_storygen\"\n",
        "    video_bucket_name = \"video_storygen\"\n",
        "    output_file = \"output.mp4\"\n",
        "    vid= merge_audio_image(audio_bucket_name,image_bucket_name,output_file,video_bucket_name)\n",
        "    if st.button(\"Generate Video\"):\n",
        "         st.spinner(text=\"Video in Progress\")\n",
        "         st.video(\"https://storage.cloud.google.com/video_storygen/output.mp4\")\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oog9y1eb2rZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "id": "ulCoJFiZ4Tde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#paste the endpoint address before clicking on submit\n",
        "!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "GP5_N7Zf4VqD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}